{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DQN_CartPole.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FjZx2ETFlR9b"},"source":["# DQN for CartPole environment"]},{"cell_type":"markdown","metadata":{"id":"b-y35OKlj_wK"},"source":["## Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"1H1tjTIhjdJg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626730890672,"user_tz":-120,"elapsed":18345,"user":{"displayName":"Nazifa Mubashshera Shemonti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhPHsKHnusPYFY8f2KhPysOf_FiqRNEn7GwI2-=s64","userId":"01827490719955449007"}},"outputId":"21a86c38-9dcc-4cad-db58-23d69435d0cb"},"source":["# Mount Drive\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FHOlvL96TFqS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626730893427,"user_tz":-120,"elapsed":317,"user":{"displayName":"Nazifa Mubashshera Shemonti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhPHsKHnusPYFY8f2KhPysOf_FiqRNEn7GwI2-=s64","userId":"01827490719955449007"}},"outputId":"755a8d9a-5d3d-4a84-b171-651c4f261599"},"source":["# Change to current directory and check\n","import os\n","os.chdir('/gdrive/MyDrive/earth-7/')\n","!ls\n","# Working directory should include ROMS and models folders"],"execution_count":2,"outputs":[{"output_type":"stream","text":["CartPole-v0  DQN_CartPole.ipynb  DQN_Pong.ipynb  models  Pong-v0  ROMS\tvideo\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rL8NDK18NpTZ"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"Otk1-2jvk51r","executionInfo":{"status":"ok","timestamp":1626730897004,"user_tz":-120,"elapsed":947,"user":{"displayName":"Nazifa Mubashshera Shemonti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhPHsKHnusPYFY8f2KhPysOf_FiqRNEn7GwI2-=s64","userId":"01827490719955449007"}}},"source":["import gym\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"IcaypR3yBPjX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626730898847,"user_tz":-120,"elapsed":363,"user":{"displayName":"Nazifa Mubashshera Shemonti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhPHsKHnusPYFY8f2KhPysOf_FiqRNEn7GwI2-=s64","userId":"01827490719955449007"}},"outputId":"7086a0cc-a228-4920-de6d-3e1aabda4b39"},"source":["# Create the environment\n","env = gym.make('CartPole-v0')\n","env.seed(1)\n","print('State shape: ', env.observation_space.shape)\n","print('Number of actions: ', env.action_space.n)\n","env.close()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["State shape:  (4,)\n","Number of actions:  2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wqENp1crSBTU"},"source":["$$\n","target\\_update\\_frequency = 10\n","$$"]},{"cell_type":"code","metadata":{"id":"g037UErNBPTM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626731128121,"user_tz":-120,"elapsed":227339,"user":{"displayName":"Nazifa Mubashshera Shemonti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhPHsKHnusPYFY8f2KhPysOf_FiqRNEn7GwI2-=s64","userId":"01827490719955449007"}},"outputId":"b14047dd-b8c0-4b80-f573-2ece20556779"},"source":["!python '/gdrive/MyDrive/earth-7/CartPole-v0/train.py' --env CartPole-v0 --evaluate_freq 10 --evaluation_episodes 5"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Best reward 22.4 so far in episode 0/1000\n","Saving model for epsilon: 0.985107956942997\n","Best reward 23.8 so far in episode 60/1000\n","Saving model for epsilon: 0.8253092519967112\n","Best reward 31.6 so far in episode 100/1000\n","Saving model for epsilon: 0.7288919505252545\n","Best reward 36.6 so far in episode 110/1000\n","Saving model for epsilon: 0.7006435725023222\n","Best reward 45.8 so far in episode 150/1000\n","Saving model for epsilon: 0.6015662644450388\n","Best reward 51.8 so far in episode 190/1000\n","Saving model for epsilon: 0.491183983502087\n","Best reward 58.0 so far in episode 200/1000\n","Saving model for epsilon: 0.45771238398155506\n","Best reward 82.8 so far in episode 250/1000\n","Saving model for epsilon: 0.3228881446301511\n","Best reward 116.0 so far in episode 270/1000\n","Saving model for epsilon: 0.2594242260828008\n","Best reward 131.0 so far in episode 290/1000\n","Saving model for epsilon: 0.19621263767635172\n","Best reward 173.6 so far in episode 300/1000\n","Saving model for epsilon: 0.16160456840014942\n","Best reward 180.0 so far in episode 310/1000\n","Saving model for epsilon: 0.1340121964884637\n","Best reward 200.0 so far in episode 330/1000\n","Saving model for epsilon: 0.0970382915854624\n","Best reward 200.0 so far in episode 340/1000\n","Saving model for epsilon: 0.08490960424424773\n","Best reward 200.0 so far in episode 360/1000\n","Saving model for epsilon: 0.06924905530750139\n","Best reward 200.0 so far in episode 370/1000\n","Saving model for epsilon: 0.06426005090270716\n","Best reward 200.0 so far in episode 380/1000\n","Saving model for epsilon: 0.06056410553657425\n","Best reward 200.0 so far in episode 400/1000\n","Saving model for epsilon: 0.055807568522702765\n","Best reward 200.0 so far in episode 420/1000\n","Saving model for epsilon: 0.05319268413488657\n","Best reward 200.0 so far in episode 450/1000\n","Saving model for epsilon: 0.051305468505763605\n","Best reward 200.0 so far in episode 460/1000\n","Saving model for epsilon: 0.05096711485559582\n","Best reward 200.0 so far in episode 470/1000\n","Saving model for epsilon: 0.050716456306517346\n","Best reward 200.0 so far in episode 480/1000\n","Saving model for epsilon: 0.05053076388619038\n","Best reward 200.0 so far in episode 490/1000\n","Saving model for epsilon: 0.05039319955776967\n","Best reward 200.0 so far in episode 500/1000\n","Saving model for epsilon: 0.05029128939675977\n","Best reward 200.0 so far in episode 510/1000\n","Saving model for epsilon: 0.050215792492611024\n","Best reward 200.0 so far in episode 520/1000\n","Saving model for epsilon: 0.05015986301041257\n","Best reward 200.0 so far in episode 530/1000\n","Saving model for epsilon: 0.05011842943092666\n","Best reward 200.0 so far in episode 540/1000\n","Saving model for epsilon: 0.05008773468029544\n","Best reward 200.0 so far in episode 550/1000\n","Saving model for epsilon: 0.050064995449748545\n","Best reward 200.0 so far in episode 560/1000\n","Saving model for epsilon: 0.050048149813435125\n","Best reward 200.0 so far in episode 570/1000\n","Saving model for epsilon: 0.05003567025911517\n","Best reward 200.0 so far in episode 580/1000\n","Saving model for epsilon: 0.05002642517788895\n","Best reward 200.0 so far in episode 590/1000\n","Saving model for epsilon: 0.0500195762532649\n","Best reward 200.0 so far in episode 600/1000\n","Saving model for epsilon: 0.05001450244511132\n","Best reward 200.0 so far in episode 610/1000\n","Saving model for epsilon: 0.0500107436755829\n","Best reward 200.0 so far in episode 620/1000\n","Saving model for epsilon: 0.050007959110628906\n","Best reward 200.0 so far in episode 630/1000\n","Saving model for epsilon: 0.050005896254174315\n","Best reward 200.0 so far in episode 640/1000\n","Saving model for epsilon: 0.0500043680525261\n","Best reward 200.0 so far in episode 650/1000\n","Saving model for epsilon: 0.050003235932900236\n","Best reward 200.0 so far in episode 660/1000\n","Saving model for epsilon: 0.0500023972380534\n","Best reward 200.0 so far in episode 670/1000\n","Saving model for epsilon: 0.05000177591762927\n","Best reward 200.0 so far in episode 680/1000\n","Saving model for epsilon: 0.050001315632138194\n","Best reward 200.0 so far in episode 690/1000\n","Saving model for epsilon: 0.05000097464425969\n","Best reward 200.0 so far in episode 700/1000\n","Saving model for epsilon: 0.05000072203422626\n","Best reward 200.0 so far in episode 710/1000\n","Saving model for epsilon: 0.05000053489611077\n","Best reward 200.0 so far in episode 720/1000\n","Saving model for epsilon: 0.05000039626078503\n","Best reward 200.0 so far in episode 730/1000\n","Saving model for epsilon: 0.050000293557209696\n","Best reward 200.0 so far in episode 740/1000\n","Saving model for epsilon: 0.05000021747252975\n","Best reward 200.0 so far in episode 750/1000\n","Saving model for epsilon: 0.05000016110761254\n","Best reward 200.0 so far in episode 760/1000\n","Saving model for epsilon: 0.05000011935145486\n","Best reward 200.0 so far in episode 770/1000\n","Saving model for epsilon: 0.05000008841773243\n","Best reward 200.0 so far in episode 780/1000\n","Saving model for epsilon: 0.05000006550146721\n","Best reward 200.0 so far in episode 800/1000\n","Saving model for epsilon: 0.05000003637830362\n","Best reward 200.0 so far in episode 820/1000\n","Saving model for epsilon: 0.050000020217984754\n","Best reward 200.0 so far in episode 840/1000\n","Saving model for epsilon: 0.050000011132542134\n","Best reward 200.0 so far in episode 850/1000\n","Saving model for epsilon: 0.05000000824719005\n","Best reward 200.0 so far in episode 860/1000\n","Saving model for epsilon: 0.05000000610966866\n","Best reward 200.0 so far in episode 870/1000\n","Saving model for epsilon: 0.05000000452615387\n","Best reward 200.0 so far in episode 880/1000\n","Saving model for epsilon: 0.05000000335305726\n","Best reward 200.0 so far in episode 890/1000\n","Saving model for epsilon: 0.05000000248400591\n","Best reward 200.0 so far in episode 900/1000\n","Saving model for epsilon: 0.05000000184019684\n","Best reward 200.0 so far in episode 910/1000\n","Saving model for epsilon: 0.05000000136325135\n","Best reward 200.0 so far in episode 920/1000\n","Saving model for epsilon: 0.05000000101022446\n","Best reward 200.0 so far in episode 930/1000\n","Saving model for epsilon: 0.05000000074839269\n","Best reward 200.0 so far in episode 940/1000\n","Saving model for epsilon: 0.05000000055442294\n","Best reward 200.0 so far in episode 950/1000\n","Saving model for epsilon: 0.050000000410726615\n","Best reward 200.0 so far in episode 960/1000\n","Saving model for epsilon: 0.05000000030427376\n","Best reward 200.0 so far in episode 970/1000\n","Saving model for epsilon: 0.050000000225411546\n","Best reward 200.0 so far in episode 980/1000\n","Saving model for epsilon: 0.050000000167239655\n","Best reward 200.0 so far in episode 990/1000\n","Saving model for epsilon: 0.05000000012389418\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yQswC53mwmBY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626731178795,"user_tz":-120,"elapsed":30512,"user":{"displayName":"Nazifa Mubashshera Shemonti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhPHsKHnusPYFY8f2KhPysOf_FiqRNEn7GwI2-=s64","userId":"01827490719955449007"}},"outputId":"f7d83c39-6fa0-448e-a6e9-8ba91f0f26db"},"source":["!python '/gdrive/MyDrive/earth-7/CartPole-v0/evaluate.py' --env CartPole-v0 --path '/gdrive/MyDrive/earth-7/models/CartPole-v0_best.pt' --n_eval_episodes 1000  "],"execution_count":6,"outputs":[{"output_type":"stream","text":["The policy got a mean return of 200.0 over 1000 episodes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7EQGtqvjSVeX"},"source":["$$\n","target\\_update\\_frequency = 1000\n","$$"]},{"cell_type":"code","metadata":{"id":"dOgkiLxGST58"},"source":["!python '/gdrive/MyDrive/earth-7/CartPole-v0/train.py' --env CartPole-v0 --evaluate_freq 10 --evaluation_episodes 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KjmZ7dWVSZLq"},"source":["!python '/gdrive/MyDrive/earth-7/CartPole-v0/evaluate.py' --env CartPole-v0 --path '/gdrive/MyDrive/earth-7/models/CartPole-v0_best.pt' --n_eval_episodes 1000  "],"execution_count":null,"outputs":[]}]}